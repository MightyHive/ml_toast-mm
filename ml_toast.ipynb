{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUymE2l9GZfO"
      },
      "source": [
        "**Copyright 2023 Google LLC.**\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "JMyTNwSJGGWg"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdRBuDb7jfh"
      },
      "source": [
        "<img align=\"left\" width=\"150\" src=\"https://services.google.com/fh/files/misc/ml_toast_logo.png\" alt=\"ml_toast_logo\" /><br><br>\n",
        "\n",
        "# üçû ML-ToAST: **M**ulti**l**ingual **To**pic Clustering of **A**ds-triggering **S**earch **T**erms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aYXRT3tCxJf"
      },
      "source": [
        "**Disclaimer: This is not an official Google product.**\n",
        "\n",
        "**üçû ML-ToAST** is an open-source tool that helps users cluster multilingual search terms captured from different time windows into semantically relevant topics. It helps advertisers / marketers surface insights related to changing consumer interest in a configurable, user-friendly, and privacy-safe manner.\n",
        "\n",
        "More information available at [github.com/google/ml_toast](https://github.com/google/ml_toast)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f4A-IWl37tK"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um6l3f0Rjm76"
      },
      "source": [
        "### Which search terms to use?\n",
        "\n",
        "We recommend extracting the Google Ads [Search Terms report](https://support.google.com/google-ads/answer/2472708) for the following periods:\n",
        " * **Last 30 days** (e.g. Nov 1 - Nov 30): it generally makes sense to look at the most recent search terms that triggered your ads.\n",
        " * **Previous 30/31 days** (e.g. Oct 1 - Oct 31): this helps provide information on those search terms that constitute your core business over those that are recently trending.\n",
        " * **Last 30 days last year** (e.g. Nov 1 - Nov 30 of the previous year): to account for seasonality effects (e.g. holiday season).\n",
        "\n",
        "We also recommend restricting the extracted search terms to a subset of *related* campaigns (e.g. all campaigns for a specific *product line* or *operating domain*) rather than all campaigns in your account. This allows the model to better capture how the search terms relate to one another, and therefore, extract more meaningful topics.\n",
        "\n",
        "The report can be downloaded from the Google Ads UI in CSV format and imported into a Google Sheets spreadsheet or a Google Cloud BigQuery table, to be used below for input/output.\n",
        "\n",
        "*Note: if you have multiple accounts operating under the same product line or domain, you can extract search terms from those accounts as well and group them all into the same Google Sheets spreadsheet / Google Cloud BigQuery table.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HHBTlVl1zht"
      },
      "source": [
        "## Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "krUBtMJeAQlf"
      },
      "outputs": [],
      "source": [
        "#@title Authenticate your user for this colab session\n",
        "import logging\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "logging.getLogger().setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ns6MdB_5OaZ8"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install tensorflow-text hdbscan umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJb_S6X0ILa2"
      },
      "source": [
        "## Input and Preprocessing - Google Sheets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1ywOMopb0gUu"
      },
      "outputs": [],
      "source": [
        "#@title Configurable params { run: 'auto' }\n",
        "\n",
        "#@markdown Enter your spreadsheet ID:\n",
        "spreadsheet_id = \"id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the main worksheet name (which should usually contain the search terms from the last month):\n",
        "input_sheet_name = \"colab-input-main\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the prefix for any additional worksheets you would also like to analyze (e.g. search terms from the previous month, previous year, etc.):\n",
        "additional_sheets_prefix = \"colab-input-lookback-\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the name of the column that contains search terms. This value should be the same across all worksheets (defaults to the column name in the Google Ads Search Terms report):\n",
        "search_terms_column = \"Search term\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <hr>Filtering settings\n",
        "\n",
        "#@markdown ***Check*** the checkbox to filter on new terms (i.e. compare search terms from the aforementioned lookback worksheets and keep only what is *new*) and ***uncheck*** to analyze search terms from the main worksheet only.\n",
        "filter_new_terms = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Enter the name of a column that contains a metric you would like to use for filtering and/or sorting (e.g. impressions):\n",
        "filter_metric_column = \"Impr.\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Use this value to indicate the maximum allowed threshold for your chosen *metric* (e.g. 1000 will filter all search terms with *metric* > 1000).<br>Set to *-1* to skip *metric* filtering.\n",
        "filter_metric_max_threshold = -1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Select the desired logical grouping (AND/OR) of the *new* and *metric* filters:\n",
        "filters_grouping = \"AND\" #@param [\"AND\", \"OR\"]\n",
        "\n",
        "# Google Ads specific params\n",
        "\n",
        "known_report_metrics = ['Clicks', 'Impr.', 'Cost']\n",
        "all_report_metrics = (\n",
        "    known_report_metrics if filter_metric_column in known_report_metrics\n",
        "    else [filter_metric_column])\n",
        "\n",
        "# Validation rules\n",
        "if not spreadsheet_id or not input_sheet_name or not search_terms_column:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure at least '\n",
        "      '\"spreadsheet_id\", \"input_sheet_name\" and \"search_terms_column\" '\n",
        "      'are provided.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sC8BrKCh0QOC"
      },
      "outputs": [],
      "source": [
        "#@title Fetch data from the input spreadsheet\n",
        "#@markdown The first row in each worksheet will be considered the **column headers** row.\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "sheets_client = gspread.authorize(creds)\n",
        "spreadsheet = sheets_client.open_by_key(spreadsheet_id)\n",
        "\n",
        "input_values = spreadsheet.worksheet(input_sheet_name).get_all_values()\n",
        "additional_sheets_values = []\n",
        "\n",
        "if filter_new_terms and additional_sheets_prefix:\n",
        "  for sheet in spreadsheet.worksheets():\n",
        "    if sheet.title.startswith(additional_sheets_prefix):\n",
        "      additional_sheets_values.append(sheet.col_values(1))\n",
        "\n",
        "input_data = pd.DataFrame(input_values[1:], columns=input_values[0])\n",
        "\n",
        "for report_metric in all_report_metrics:\n",
        "  if report_metric in input_data.columns:\n",
        "    input_data[report_metric] = pd.to_numeric(\n",
        "        input_data[report_metric].str.replace(',', ''))\n",
        "\n",
        "print(\n",
        "    f'Worksheet: {input_sheet_name}\\nNumber of rows: {len(input_data)}\\n'\n",
        "    'First 5 rows:')\n",
        "input_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xD4cB0YElXtu"
      },
      "outputs": [],
      "source": [
        "#@title Extract search terms and apply the defined filters\n",
        "\n",
        "def add_filter(existing_filter, new_filter):\n",
        "  if filters_grouping == 'AND':\n",
        "    return existing_filter & new_filter\n",
        "  return existing_filter | new_filter\n",
        "\n",
        "additional_data = [\n",
        "    pd.DataFrame(sheet_values[1:], columns=[sheet_values[0]])\n",
        "    for sheet_values in additional_sheets_values]\n",
        "\n",
        "data_unfiltered = input_data.copy()\n",
        "\n",
        "series_filter = (filters_grouping == 'AND')\n",
        "applied_filters = []\n",
        "\n",
        "if additional_data:\n",
        "  data_unfiltered = (\n",
        "      data_unfiltered.merge(pd.concat(additional_data).drop_duplicates(),\n",
        "                    on=search_terms_column,\n",
        "                    how='left',\n",
        "                    indicator=True))\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "          data_unfiltered['_merge'] == 'left_only'))\n",
        "  applied_filters.append('filter_new_terms')\n",
        "\n",
        "if filter_metric_column and filter_metric_max_threshold > 0:\n",
        "  series_filter = add_filter(\n",
        "      existing_filter=series_filter, new_filter=(\n",
        "      data_unfiltered[filter_metric_column] <= filter_metric_max_threshold))\n",
        "  applied_filters.append(\n",
        "      f'filter_metric_max_threshold < {filter_metric_max_threshold}')\n",
        "\n",
        "main_input_data = (\n",
        "    data_unfiltered[series_filter] if applied_filters else data_unfiltered)\n",
        "\n",
        "if '_merge' in main_input_data.columns:\n",
        "  main_input_data = main_input_data.drop(columns='_merge')\n",
        "\n",
        "if filter_metric_column in main_input_data.columns:\n",
        "  main_input_data = main_input_data.sort_values(\n",
        "      by=filter_metric_column, ascending=False)\n",
        "\n",
        "print('\\n'.join([\n",
        "    f'Filtered data - total number of rows: {len(main_input_data)}',\n",
        "    f'Filters applied: {applied_filters}',\n",
        "    (\n",
        "        f\"Filters logical grouping: '{filters_grouping}'\"\n",
        "        if len(applied_filters) > 1 else ''),\n",
        "    'First 5 rows:']))\n",
        "main_input_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTf12tzL4QpW"
      },
      "source": [
        "## Input and Preprocessing - Google Cloud BigQuery\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C6-p6Avp4UEh"
      },
      "outputs": [],
      "source": [
        "#@title Configurable params { run: 'auto' }\n",
        "\n",
        "#@markdown Enter your Google Cloud Project ID:\n",
        "gcp_project_id = \"id-goes-here\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the SQL query you would like to execute to pull data from BigQuery\n",
        "#@markdown (*Expand this cell to view a sample query for the [Google Ads BigQuery Data Transfer](https://cloud.google.com/bigquery/docs/google-ads-transfer)*):\n",
        "bq_input_query = \"SELECT * FROM `dataset.table` WHERE column = \\\"value\\\" ORDER BY column\" #@param {type:\"string\"}\n",
        "\n",
        "# Google Ads BigQuery Data Transfer sample query\n",
        "gcp_dataset_name = '<dataset>'\n",
        "gcp_ads_transfer_tablename_suffix = '_<suffix>'\n",
        "bg_input_query_sample = f\"\"\"\n",
        "SELECT\n",
        "  S.search_term_view_search_term AS `Search term`, \n",
        "  S.segments_search_term_match_type AS `Match type`,\n",
        "  S.search_term_view_status AS `Added or Excluded`, \n",
        "  C.campaign_name AS `Campaign`, \n",
        "  C.campaign_advertising_channel_type `Campaign type`, \n",
        "  C.campaign_bidding_strategy_type AS `Bid strategy type`, \n",
        "  A.ad_group_name AS `Ad group`,\n",
        "  SUM(S.metrics_impressions) AS `Impr`, \n",
        "  SUM(S.metrics_clicks) AS `Clicks`, \n",
        "  SUM(S.metrics_cost_micros) AS `Cost`,\n",
        "FROM\n",
        "  `{gcp_project_id}.{gcp_dataset_name}.ads_SearchQueryStats{gcp_ads_transfer_tablename_suffix}` AS S\n",
        "INNER JOIN \n",
        "  `{gcp_project_id}.{gcp_dataset_name}.ads_Campaign{gcp_ads_transfer_tablename_suffix}` AS C USING (campaign_id)\n",
        "INNER JOIN \n",
        "  `{gcp_project_id}.{gcp_dataset_name}.ads_AdGroup{gcp_ads_transfer_tablename_suffix}` AS A USING (ad_group_id)\n",
        "GROUP BY\n",
        "  S.search_term_view_search_term, \n",
        "  S.segments_search_term_match_type,\n",
        "  S.search_term_view_status, \n",
        "  C.campaign_name, \n",
        "  C.campaign_advertising_channel_type, \n",
        "  C.campaign_bidding_strategy_type, \n",
        "  A.ad_group_name\n",
        "ORDER BY `Impr` DESC, `Search term`;\n",
        "\"\"\"\n",
        "\n",
        "#@markdown Enter the name of the column that contains search terms:\n",
        "search_terms_column = \"Search term\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the name of the BigQuery dataset where output should be stored:\n",
        "bq_output_dataset = \"ml_toast_output\" #@param {type:\"string\"}\n",
        "\n",
        "# Validation rules\n",
        "if not gcp_project_id or not bq_input_query:\n",
        "  raise ValueError(\n",
        "      'Invalid input! Please make sure a valid GCP '\n",
        "      '\"project_id\" and \"bq_query\" are provided.')\n",
        "\n",
        "if not bq_output_dataset:\n",
        "  print(\n",
        "      'WARNING - \"bq_output_dataset\" is not set. '\n",
        "      'Writing output to BigQuery will fail!'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7KTDI0oa_FqL"
      },
      "outputs": [],
      "source": [
        "#@title Fetch input data from GCP BigQuery\n",
        "%%bigquery main_input_data --project $gcp_project_id\n",
        "$bq_input_query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2WO7EAR5sYi"
      },
      "source": [
        "## Input and Preprocessing - Common Settings\n",
        "\n",
        "Run these cells regardless of the input type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7K8mdtBJ57FZ"
      },
      "outputs": [],
      "source": [
        "#@title Configurable params { run: 'auto' }\n",
        "\n",
        "#@markdown Enter the name of the column that represents the **match type** for each search term (defaults to the column name in the Google Ads Search Terms report):\n",
        "match_type_column = \"Match type\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the *match type* value that corresponds to Broad Match (defaults to the column name in the Google Ads Search Terms report):\n",
        "match_type_broad = \"Broad match\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown <hr>Advanced settings\n",
        "\n",
        "#@markdown Enter a comma-separated list of *stop words* which should be excluded from all generated topics:\n",
        "stop_words = \"stop1, stop2\" #@param {type:\"string\"}\n",
        "\n",
        "if stop_words:\n",
        "  stop_words = stop_words.replace(', ', ',').split(',')\n",
        "else:\n",
        "  stop_words = None\n",
        "\n",
        "#@markdown ***Check*** the checkbox to perform hyperparameter tuning for UMAP + HDBSCAN (increases processing time by a factor of ~3).<br>\n",
        "#@markdown Despite the time factor, we **highly** recommend using this to provide the optimal results for the given input.<br>\n",
        "#@markdown ***Uncheck*** to use the default clustering parameters.\n",
        "hyperparameter_tuning = False #@param {type:\"boolean\"}\n",
        "\n",
        "# Debugging params\n",
        "# Calculates performance metrics for the output topics, which will be done in\n",
        "# the provided LookerStudio dashboard (set to True if not using the dashboard)\n",
        "output_topic_metrics = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qd_j_xpH9cZc"
      },
      "outputs": [],
      "source": [
        "#@title Display the first 5 rows of the fetched data\n",
        "\n",
        "if main_input_data.empty:\n",
        "  raise ValueError(\n",
        "      'No data was fetched. Please run all cells in either the \"Google Sheets\" '\n",
        "      'or \"Google Cloud BigQuery\" Input and Preprocessing section first.')\n",
        "\n",
        "main_input_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BxZ5gdWG56Oq"
      },
      "outputs": [],
      "source": [
        "#@title Extract 'Broad Match' and 'non Broad Match' terms from the fetched data\n",
        "broad_match_groups = {}\n",
        "\n",
        "if match_type_column in main_input_data.columns:\n",
        "  broad_match_terms = main_input_data.copy()\n",
        "  broad_match_terms = broad_match_terms[\n",
        "      main_input_data[match_type_column] == match_type_broad]\n",
        "\n",
        "  non_broad_match_terms = main_input_data.copy()\n",
        "  non_broad_match_terms = non_broad_match_terms[\n",
        "      main_input_data[match_type_column] != match_type_broad]\n",
        "\n",
        "  if not broad_match_terms.empty:\n",
        "    broad_match_groups['broad_match_terms'] = broad_match_terms\n",
        "\n",
        "  if not non_broad_match_terms.empty:\n",
        "    broad_match_groups['non_broad_match_terms'] = non_broad_match_terms\n",
        "\n",
        "  print(\n",
        "      'Extracted:\\n'\n",
        "      f' - All terms where \"{match_type_column}\" is \"{match_type_broad}\" '\n",
        "      f'from the filtered data. Number of rows: {len(broad_match_terms)}')\n",
        "  print(\n",
        "      'Extracted:\\n'\n",
        "      f' - All terms where \"{match_type_column}\" is NOT \"{match_type_broad}\" '\n",
        "      f'from the filtered data. Number of rows: {len(non_broad_match_terms)}')\n",
        "else:\n",
        "  print(\n",
        "      f'No column \"{match_type_column}\" found in the input data. '\n",
        "      'Skipping extraction of Broad Match terms.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aphRjaaviXKI"
      },
      "source": [
        "## Topic Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mtoxiM9RyVaV"
      },
      "outputs": [],
      "source": [
        "#@title Import the topic clustering library\n",
        "!echo \"Restoring working directory to root...\"\n",
        "%cd /content\n",
        "!rm -rf ml_toast && git clone https://github.com/google/ml_toast.git\n",
        "!echo \"Changing working directory to ml_toast...\"\n",
        "%cd ml_toast\n",
        "\n",
        "from ml_toast import topic_clustering as topic_clustering_lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qcgsRGcg0maR"
      },
      "outputs": [],
      "source": [
        "#@title Use the library to determine topics for all input groups\n",
        "terms_input_data_dict = {'input_terms': main_input_data} | broad_match_groups\n",
        "\n",
        "for key, terms_input_data in terms_input_data_dict.items():\n",
        "  topic_clustering = topic_clustering_lib.TopicClustering(\n",
        "      data_id=key,\n",
        "      input_col=search_terms_column,\n",
        "      stop_words=stop_words,\n",
        "      do_hdbscan_hyperopt=hyperparameter_tuning)\n",
        "  topics_kmeans, topics_hdbscan = topic_clustering.determine_topics(\n",
        "      terms_input_data)\n",
        "  terms_input_data['Topic'] = topics_kmeans\n",
        "  terms_input_data['Additional Topics'] = topics_hdbscan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZupJfkwIHml"
      },
      "source": [
        "## Output\n",
        "\n",
        "Run only one of the cells below, depending on the origin of your input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UEs6V8SS4xSb"
      },
      "outputs": [],
      "source": [
        "#@title Write results back to the input spreadsheet\n",
        "#@markdown New worksheets with the prefix **colab-** will be appended to the spreadsheet,\n",
        "#@markdown or overwritten if they already exist.\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "for key, terms_input_data in terms_input_data_dict.items():\n",
        "  try:\n",
        "    output_sheet = spreadsheet.worksheet(f'colab-{key}-output')\n",
        "    output_sheet.clear()\n",
        "  except gspread.exceptions.WorksheetNotFound:\n",
        "    output_sheet = spreadsheet.add_worksheet(\n",
        "        f'colab-{key}-output',\n",
        "        rows=len(terms_input_data),\n",
        "        cols=len(terms_input_data.columns))\n",
        "  set_with_dataframe(\n",
        "      output_sheet, terms_input_data, include_column_header=True)\n",
        "\n",
        "  if output_topic_metrics:\n",
        "    for topics_type in ['Topic', 'Additional Topics']:\n",
        "      cluster_metrics = pd.DataFrame()\n",
        "      cluster_metrics['Topic'] = terms_input_data[topics_type]\n",
        "      for report_metric in all_report_metrics:\n",
        "        if report_metric in terms_input_data.columns:\n",
        "          cluster_metrics[report_metric] = terms_input_data[report_metric]\n",
        "\n",
        "      cluster_metrics = cluster_metrics.groupby(by='Topic', sort=False).agg(\n",
        "          ['mean', 'median', 'min', 'max', 'std', 'var'])\n",
        "      cluster_metrics.insert(loc=0, column='Topic', value=cluster_metrics.index)\n",
        "      cluster_metrics.insert(\n",
        "          loc=1,\n",
        "          column='Count',\n",
        "          value=terms_input_data.groupby(by=topics_type, sort=False).count()[\n",
        "              search_terms_column])\n",
        "      cluster_metrics = cluster_metrics.sort_values(by='Count', ascending=False)\n",
        "      cluster_metrics_key = (\n",
        "          f\"{key}_{topics_type.lower().replace(' ', '_')}\")\n",
        "\n",
        "      try:\n",
        "        metrics_sheet = spreadsheet.worksheet(\n",
        "            f'colab-{cluster_metrics_key}-metrics')\n",
        "        metrics_sheet.clear()\n",
        "      except gspread.exceptions.WorksheetNotFound:\n",
        "        metrics_sheet = spreadsheet.add_worksheet(\n",
        "            f'colab-{cluster_metrics_key}-metrics',\n",
        "            rows=len(cluster_metrics),\n",
        "            cols=len(cluster_metrics.columns))\n",
        "      set_with_dataframe(\n",
        "          metrics_sheet, cluster_metrics, include_column_header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-X5C_O4MAUeI"
      },
      "outputs": [],
      "source": [
        "#@title Write results to new GCP BigQuery tables\n",
        "#@markdown **Optional**: Modify the `destination_table` and `if_exists` parameters below as desired (e.g. adding a prefix to the name of the created tables).\n",
        "\n",
        "for key, terms_input_data in terms_input_data_dict.items():\n",
        "  terms_input_data.to_gbq(\n",
        "      destination_table=f'{bq_output_dataset}.{key}', # `dataset.tablename`\n",
        "      project_id=gcp_project_id,\n",
        "      if_exists='replace',  # fail/replace/append\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l-ceTbYbfV-"
      },
      "source": [
        "### Visualize the generated topics in LookerStudio\n",
        "\n",
        "ML-ToAST provides a template LookerStudio dashboard to help you visualize the generated topics and quickly surface insights.\n",
        "\n",
        "Use [this link](https://lookerstudio.google.com/c/u/0/reporting/8bc2240e-a919-4916-9c7f-daf72f75bf42/preview) to create a copy of the dashboard and get started! All you would need to do is map the data sources used by the dashboard to the spreadsheet / BigQuery tables used for the input and output above. The dashboard contains both types of data sources, so please delete the ones that are irrelevant / unused."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SYaT0Zrhdfb"
      },
      "source": [
        "### How was the sample data generated?\n",
        "\n",
        "All data in the template LookerStudio dashboard was generated using the `Faker` library as shown by the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uwvfqHCoh90x"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip install Faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EHjro_l7iBTG"
      },
      "outputs": [],
      "source": [
        "#@title Generate sample data with Faker\n",
        "#@markdown The generated data format resembles that of a typical Google Ads Search Terms report.\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "\n",
        "GADS_MATCH_TYPES = [\n",
        "    'Broad match',\n",
        "    'Exact match',\n",
        "    'Exact match (close variant)',\n",
        "    'Phrase match',\n",
        "    'Phrase match (close variant)',\n",
        "]\n",
        "\n",
        "fake = Faker(['en'])\n",
        "rows = [['Search term', 'Match type', 'Campaign', 'Ad group', 'Impr.', 'Clicks']]\n",
        "\n",
        "for i in range (1, 50000):\n",
        "  row = [\n",
        "      fake.text(max_nb_chars=50).replace('.', ''),\n",
        "      fake.random_element(elements=GADS_MATCH_TYPES),\n",
        "      f'Campaign {random.randint(1, 10)}',\n",
        "      f'Ad group {random.randint(1, 10)}',\n",
        "      random.randint(1, 10000),\n",
        "      random.randint(1, 10000),\n",
        "    ]\n",
        "  rows.append(row)\n",
        "\n",
        "generated_terms = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "generated_terms.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Adc0M9QfjSJ1"
      },
      "outputs": [],
      "source": [
        "#@title Output to csv\n",
        "#@markdown The file will be saved in the default 'home' folder on Colab (`/content/`) and can be downloaded from there.\n",
        "generated_terms.to_csv('/content/faker_sample.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9f4A-IWl37tK",
        "OJb_S6X0ILa2",
        "aTf12tzL4QpW",
        "0SYaT0Zrhdfb"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
